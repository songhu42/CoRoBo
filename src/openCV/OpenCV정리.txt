ì§€ê¸ˆê¹Œì§€ ì œê°€ ë§Œë“  OpenCV í•˜ê² ìŠµë‹ˆë‹¤. 


** pip install ultralytics ** 

- YOLOv8(You Only Look Once)ì˜ ìµœì‹  ë²„ì „ì„ ì œê³µí•˜ëŠ” Ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

- YOLOëŠ” ê°ì²´ íƒì§€, ì´ë¯¸ì§€ ë¶„í• , ê·¸ë¦¬ê³  ì¶”ì  ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.
-  YOLOv8ê³¼ ê´€ë ¨ëœ ê¸°ëŠ¥ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
ì‚¬ìš© ì´ìœ : YOLOv8 ëª¨ë¸ì„ ì´ìš©í•´ ê°ì²´ë¥¼ ê°ì§€í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ë˜ëŠ” ì²˜ë¦¬ë¥¼ í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.

ì„¤ì¹˜ëœ ì£¼ìš” ê¸°ëŠ¥: YOLO ëª¨ë¸ì˜ í•™ìŠµ ë° ì¶”ë¡ . ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš©. ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ.


** pip install mediapipe **
- Googleì—ì„œ ì œê³µí•˜ëŠ” MediaPipe ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
- MediaPipeëŠ” ì‹¤ì‹œê°„ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë„êµ¬ë¡œ, í¬ì¦ˆ ì¶”ì •, ì† ì¶”ì , ì–¼êµ´ ê°ì§€ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ì‚¬ìš© ì´ìœ :
- í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•´ MediaPipeì˜ Pose Estimation ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„¤ì¹˜í•©ë‹ˆë‹¤.
- MediaPipeëŠ” GPUë¥¼ ì§€ì›í•˜ë©°, ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì„¤ì¹˜ëœ ì£¼ìš” ê¸°ëŠ¥: Pose: ì‚¬ëŒì˜ ìì„¸ ë° ê´€ì ˆ ìœ„ì¹˜ ì¶”ì •. Hands: ì† ì¶”ì  ë° ì†ê°€ë½ ê´€ì ˆ ê°ì§€, Face Mesh: ì–¼êµ´ì˜ 3D ë©”ì‹œ ìƒì„±, Objectron: 3D ê°ì²´ ê°ì§€, ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ëŠ¥


** sudo apt-get install qtwayland5 **
- Qt Wayland ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
- QtëŠ” GUI ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- WaylandëŠ” X ì„œë²„ë¥¼ ëŒ€ì²´í•˜ëŠ” ë””ìŠ¤í”Œë ˆì´ ì„œë²„ í”„ë¡œí† ì½œì´ë©°, Qt WaylandëŠ” Qt ì• í”Œë¦¬ì¼€ì´ì…˜ì´ Wayland í™˜ê²½ì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.

MediaPipe ë° OpenCVê°€ GUI(ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ í™”ë©´)ë¥¼ ë Œë”ë§í•  ë•Œ, Qt ê¸°ë°˜ ì°½ í‘œì‹œë¥¼ ìœ„í•´ ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
íŠ¹íˆ, **Wayland ê¸°ë°˜ í™˜ê²½(Ubuntu 22.04 ë“±)**ì—ì„œ OpenCV ì°½ í‘œì‹œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

------------------------------------------------------------------------------------

1. test(yolo).py

ìœ„ ì½”ë“œëŠ” MediaPipeì™€ YOLOv8ì„ í™œìš©í•˜ì—¬ ë¹„ë””ì˜¤ì—ì„œ ì‚¬ëŒì„ íƒì§€í•˜ê³ , íƒì§€ëœ ì‚¬ëŒ ì˜ì—­ì— ëŒ€í•´ í¬ì¦ˆ ì¶”ì •ì„ ìˆ˜í–‰í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ì£¼ìš” ë¶€ë¶„ì„ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë¸ ì´ˆê¸°í™”
```Python

import cv2
import mediapipe as mp
import numpy as np
from ultralytics import YOLO
import time

```

- cv2 (OpenCV): ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì²˜ë¦¬.
- mediapipe: í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬.
- ultralytics: YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ íƒì§€.
- time: FPS ê³„ì‚°ì„ ìœ„í•œ ì‹œê°„ ì¸¡ì •.

```Python

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, model_complexity=2)
mp_drawing = mp.solutions.drawing_utils

```

- MediaPipe í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™”:
- min_detection_confidence: íƒì§€ ì •í™•ë„ ê¸°ì¤€ê°’.
- min_tracking_confidence: ì¶”ì  ì •í™•ë„ ê¸°ì¤€ê°’.
- model_complexity: ëª¨ë¸ ë³µì¡ë„ ìˆ˜ì¤€ (0: ê°€ë³ê³  ë¹ ë¦„, 2: ë” ì •í™•í•¨).

```Python

yolo_model = YOLO("yolov8n.pt")

```
- yolov8n.pt: YOLOv8 nano ëª¨ë¸(ê°€ì¥ ê°€ë²¼ìš´ ë²„ì „)ì„ ì‚¬ìš©

```Python

capture = cv2.VideoCapture("/home/test/Desktop/CoRoBo/src/imgs/nn.mp4")
s_factor = 0.5  # í™”ë©´ ì¶•ì†Œ ë¹„ìœ¨
frameCount = 0
start_time = time.time()

```

- ë¹„ë””ì˜¤ íŒŒì¼ ì½ê¸°: ì§€ì •ëœ ê²½ë¡œì—ì„œ ë¹„ë””ì˜¤ë¥¼ ë¡œë“œ.
- s_factor: í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ê¸° ì „, ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì¶•ì†Œ ë¹„ìœ¨ì„ ì„¤ì • (50%ë¡œ ì¶•ì†Œ)

```Python

while True:
    ret, frame = capture.read()
    if not ret:
        break

```

- ret: í”„ë ˆì„ ì½ê¸° ì„±ê³µ ì—¬ë¶€.
- frame: í˜„ì¬ ì½ì€ í”„ë ˆì„.
- ë¹„ë””ì˜¤ê°€ ëë‚˜ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œ.

```Python
frame_resized = cv2.resize(frame, None, fx=s_factor, fy=s_factor, interpolation=cv2.INTER_AREA)
```
- ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì„¤ì •í•œ ì¶•ì†Œ ë¹„ìœ¨ë¡œ ë¦¬ìƒ˜í”Œë§í•˜ì—¬ ì²˜ë¦¬ ì†ë„ë¥¼ ë†’ì„

```Python

results = yolo_model(frame_resized)
detections = results[0].boxes

```
- YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ íƒì§€ ìˆ˜í–‰.
- results[0].boxes: íƒì§€ëœ ê°ì²´ì˜ ê²½ê³„ ìƒì, í´ë˜ìŠ¤ ID, ì‹ ë¢°ë„ ì •ë³´ë¥¼ í¬í•¨.

```Python

for detection in detections:
    xmin, ymin, xmax, ymax = detection.xyxy[0]
    conf = detection.conf[0]
    class_id = int(detection.cls[0])
    if class_id == 0 and conf > 0.5:

```

- class_id == 0: ì‚¬ëŒ í´ë˜ìŠ¤ë§Œ í•„í„°ë§.
- conf > 0.5: ì‹ ë¢°ë„ê°€ 50% ì´ìƒì¸ ê²½ìš°ë§Œ ì„ íƒ.
- ê²½ê³„ ìƒì ì¢Œí‘œë¥¼ ì–»ê³ , ì¶•ì†Œëœ í”„ë ˆì„ ë¹„ìœ¨ì„ ë³´ì •í•˜ì—¬ ì›ë˜ í¬ê¸° ì¢Œí‘œë¡œ ë³€í™˜.

MediaPipe í¬ì¦ˆ ì¶”ì •
```Python

person_frame = frame[ymin:ymax, xmin:xmax]
rgb_person_frame = cv2.cvtColor(person_frame, cv2.COLOR_BGR2RGB)
result_pose = pose.process(rgb_person_frame)
if result_pose.pose_landmarks:
    mp_drawing.draw_landmarks(person_frame, result_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)


```

- íƒì§€ëœ ì‚¬ëŒ ì˜ì—­(person_frame)ì„ ì˜ë¼ëƒ„.
- MediaPipeëŠ” RGB ì´ë¯¸ì§€ë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ ìƒ‰ìƒ ê³µê°„ ë³€í™˜.
- í¬ì¦ˆ ì¶”ì •ì„ ìˆ˜í–‰í•˜ê³ , í¬ì¦ˆ ëœë“œë§ˆí¬ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì˜ì—­ì— ëœë“œë§ˆí¬ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.

```Python

cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
cv2.putText(frame, 'Person', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

```
- YOLO íƒì§€ ê²°ê³¼ì— ê²½ê³„ ìƒìë¥¼ ê·¸ë¦¬ë©°, "Person" í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œ.

FPS ê³„ì‚°

```Python

fps = frameCount / (end_time - start_time)
cv2.putText(frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

```
- í”„ë ˆì„ ìˆ˜ì™€ ê²½ê³¼ ì‹œê°„ì„ ì´ìš©í•˜ì—¬ FPSë¥¼ ê³„ì‚°.
- í˜„ì¬ í”„ë ˆì„ì˜ ì¢Œì¸¡ ìƒë‹¨ì— FPS í‘œì‹œ.


ì¢…ë£Œ ì¡°ê±´

```Python

key = cv2.waitKey(20)
if key == 27:  # ESC í‚¤
    break

```
 - ESC í‚¤ ì…ë ¥ ì‹œ ë£¨í”„ ì¢…ë£Œ.
```Python

capture.release()
cv2.destroyAllWindows()

```
- ë¹„ë””ì˜¤ ìº¡ì²˜ ë° GUI ì°½ í•´ì œ.

------------------------------------------------------------------------------------

test(yolo2).py

ë™ì˜ìƒ ë° ëª¨ë¸ ì´ˆê¸°í™”

```Python

video_path = "/home/test/Desktop/CoRoBo/src/imgs/ss.mp4"
VideoSignal = cv2.VideoCapture(video_path)
model = YOLO("yolov8n.pt")

```

- video_path: ë¶„ì„í•  ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
- VideoSignal: OpenCVë¡œ ë™ì˜ìƒ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
- YOLO("yolov8n.pt"): YOLOv8 ê²½ëŸ‰ ëª¨ë¸(yolov8n.pt)ì„ ë¡œë“œí•©ë‹ˆë‹¤. ë‹¤ë¥¸ YOLOv8 ëª¨ë¸(yolov8s.pt, yolov8m.pt)ë„ ì‚¬ìš© ê°€ëŠ¥.

í¬ê¸° ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”

```Python

reference_object_height_cm = 170  # ê¸°ì¤€ ê°ì²´ì˜ ì‹¤ì œ í¬ê¸°(cm)
focal_length_px = 800  # ì¹´ë©”ë¼ì˜ ì´ˆì  ê±°ë¦¬ (ì„ì˜ ì„¤ì •)
reference_object_height_px = 250  # ê¸°ì¤€ ê°ì²´(ì‚¬ëŒ)ì˜ í”½ì…€ ë†’ì´

```

- ê¸°ì¤€ ê°ì²´(ì‚¬ëŒ)
- reference_object_height_cm: ì‹¤ì œ ë†’ì´ë¥¼ 170cmë¡œ ê°€ì •(ì‚¬ëŒ í‚¤).
- reference_object_height_px: ë™ì˜ìƒì—ì„œ í•´ë‹¹ ê°ì²´ì˜ í”½ì…€ ë‹¨ìœ„ ë†’ì´.
- focal_length_px: ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬(í”½ì…€ ë‹¨ìœ„)ëŠ” ë³´ì •ì— í•„ìš”í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ëŒ€ëµì ì¸ ê°’ì„ ì‚¬ìš©.

í”„ë ˆì„ ì½ê¸° ë° íƒì§€

```

ret, frame = VideoSignal.read()
if not ret:
    print("ë™ì˜ìƒ ì¬ìƒì´ ëë‚¬ìŠµë‹ˆë‹¤.")
    break

```

í”„ë ˆì„ ì½ê¸°
- ret: í”„ë ˆì„ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆëŠ”ì§€ í™•ì¸.
- frame: í˜„ì¬ ì½ì€ í”„ë ˆì„.
- ë™ì˜ìƒì´ ëë‚˜ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.


YOLOv8 íƒì§€

```Python

results = model(frame)
detections = results[0].boxes

```

- YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì—ì„œ ê°ì²´ íƒì§€ ìˆ˜í–‰.
- results[0].boxes: íƒì§€ëœ ê°ì²´ì˜ ê²½ê³„ ìƒì, í´ë˜ìŠ¤ ID, ì‹ ë¢°ë„ ì •ë³´ë¥¼ í¬í•¨

íƒì§€ ê²°ê³¼ ì²˜ë¦¬

```Python

boxes = detections.xyxy.cpu().numpy()
confidences = detections.conf.cpu().numpy()
class_ids_detected = detections.cls.cpu().numpy().astype(int)
class_names = results[0].names

```

- boxes: íƒì§€ëœ ê°ì²´ì˜ ê²½ê³„ ìƒì ì¢Œí‘œ [x1, y1, x2, y2] (ì¢Œìƒë‹¨ ë° ìš°í•˜ë‹¨).
- confidences: ê° ê°ì²´ íƒì§€ì˜ ì‹ ë¢°ë„ (0~1).
- class_ids_detected: íƒì§€ëœ í´ë˜ìŠ¤ì˜ IDë“¤.
- class_names: ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡ (ì˜ˆ: "person", "car" ë“±).

íƒì§€ëœ ê°ì²´ ë†’ì´ ê³„ì‚°

```Python

for i, box in enumerate(boxes):
    if confidences[i] > 0.5:  # ì‹ ë¢°ë„ 0.5 ì´ìƒì¸ ê²½ìš° ì²˜ë¦¬
        x1, y1, x2, y2 = map(int, box[:4])
        object_height_px = y2 - y1  # ê°ì²´ì˜ í”½ì…€ ë†’ì´
        object_height_cm = (object_height_px * reference_object_height_cm) / reference_object_height_px


```
- ì‹ ë¢°ë„ 50% ì´ìƒì¸ ê°ì²´ë§Œ ì²˜ë¦¬.
- object_height_px: ê²½ê³„ ìƒìë¡œë¶€í„° ê°ì²´ì˜ ë†’ì´(í”½ì…€ ë‹¨ìœ„)ë¥¼ ê³„ì‚°.
- object_height_cm: ê¸°ì¤€ ê°ì²´ì™€ì˜ ë¹„ìœ¨ì„ ì´ìš©í•´ ì‹¤ì œ ë†’ì´(cm)ë¡œ ë³€í™˜
[ex: ğŸ“ ê°ì²´ ë†’ì´(cm) = (ğŸ–¼ï¸ ê°ì²´ ë†’ì´(px) Ã— ğŸ¯ ê¸°ì¤€ ë†’ì´(cm)) Ã· ğŸ–¼ï¸ ê¸°ì¤€ ë†’ì´(px)]


ê²°ê³¼ í‘œì‹œ

```Python

cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 5)
cv2.putText(frame, f"{label} {confidence:.2f} ({object_height_cm:.2f} cm)", 
            (x1, y1 - 10), cv2.FONT_ITALIC, 0.5, (255, 255, 255), 1)

```

- ê²½ê³„ ìƒì: íƒì§€ëœ ê°ì²´ ì£¼ë³€ì— ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¥¼ ê·¸ë¦¼.
- ë ˆì´ë¸”ê³¼ í¬ê¸° ì •ë³´:
- í´ë˜ìŠ¤ ì´ë¦„, ì‹ ë¢°ë„, ë†’ì´(cm)ë¥¼ í‘œì‹œ.
ì˜ˆ: Person 0.89 (168.23 cm).

------------------------------------------------------------------------------------

test(yolo_Hough transform).py

YOLO ëª¨ë¸ ì¤€ë¹„

```Python

from ultralytics import YOLO
model = YOLO('yolov8n.pt')

```

- YOLOv8ì˜ ê²½ëŸ‰ ëª¨ë¸(yolov8n.pt)ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- YOLOëŠ” í”„ë ˆì„ì—ì„œ ì°¨ëŸ‰ ë“± íŠ¹ì • ê°ì²´ë¥¼ ê°ì§€í•˜ê³ , ê²½ê³„ ìƒìì™€ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

ë™ì˜ìƒ ë¡œë“œ

```Python

capture = cv2.VideoCapture("/home/test/Desktop/CoRoBo/src/imgs/rrr.mp4")

```
- ì§€ì •í•œ ë™ì˜ìƒ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ì½ìŠµë‹ˆë‹¤.
- capture.isOpened()ë¡œ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì—´ë ¸ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

ì—£ì§€ ê²€ì¶œ (Canny Edge Detection)

```Python

def detect_edges(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)
    return edges

```

- ì…ë ¥ í”„ë ˆì„ì„ í‘ë°± ë³€í™˜ â†’ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ â†’ ìºë‹ˆ ì—£ì§€ ê²€ì¶œì„ í†µí•´ ì°¨ì„ ì˜ ì—£ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
**ì—£ì§€ ê²€ì¶œ(Canny)**ì€ í”½ì…€ ê°„ ê°•í•œ ë³€í™”(ê²½ê³„)ë¥¼ ì°¾ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

ê´€ì‹¬ ì˜ì—­ ë§ˆìŠ¤í‚¹ (Region of Interest, ROI)

```Python

def region_of_interest(edges):
    height, width = edges.shape
    mask = np.zeros_like(edges)
    polygon = np.array([
        [(0, height), (width, height), (int(width / 2), int(height / 2))]
    ], np.int32)
    cv2.fillPoly(mask, polygon, 255)
    cropped_edges = cv2.bitwise_and(edges, mask)
    return cropped_edges


```

- ì‚¼ê°í˜• í˜•íƒœì˜ ê´€ì‹¬ ì˜ì—­ì„ ì§€ì •í•˜ì—¬ ì°¨ì„ ì´ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¶€ë¶„ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
- ê²°ê³¼ì ìœ¼ë¡œ ì°¨ì„  ì£¼ë³€ì˜ ì—£ì§€ë“¤ë§Œ ë‚¨ê¹ë‹ˆë‹¤.


í—ˆí”„ ë³€í™˜ì„ í†µí•œ ë¼ì¸ ê²€ì¶œ

```Python

def detect_line_segments(cropped_edges):
    rho = 1
    angle = np.pi / 180
    min_threshold = 20
    line_segments = cv2.HoughLinesP(cropped_edges, rho, angle, min_threshold,
                                    np.array([]), minLineLength=30, maxLineGap=50)
    return line_segments


```

- í—ˆí”„ ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ì°¨ì„ ì˜ ì§ì„  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
- rho: ì§ì„ ì„ ë‚˜íƒ€ë‚´ëŠ” ê±°ë¦¬ ê°„ê²© (1í”½ì…€ ë‹¨ìœ„).
- angle: ì§ì„  ê°ë„ì˜ ê°„ê²© (1ë„ ë‹¨ìœ„ë¡œ ë³€í™˜).
- minLineLength: ì§ì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ ê¸¸ì´.
- maxLineGap: ì„  ì‚¬ì´ ìµœëŒ€ ê°„ê²©.


ì°¨ì„  í‰ê· í™” ë° ì¤‘ì‹¬ì„  ê³„ì‚°

```Python

def average_slope_intercept(frame, line_segments):
    # ì§ì„ ì˜ ê¸°ìš¸ê¸°ì™€ yì ˆí¸ ê³„ì‚°
    for x1, y1, x2, y2 in line_segment:
        fit = np.polyfit((x1, x2), (y1, y2), 1)


```

- í—ˆí”„ ë³€í™˜ì—ì„œ ê²€ì¶œëœ ì§ì„ ì„ ì™¼ìª½ ì°¨ì„ ê³¼ ì˜¤ë¥¸ìª½ ì°¨ì„ ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ì°¨ì„ ì˜ í‰ê·  ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
- ê²€ì¶œëœ ì°¨ì„ ì´ ê¸°ìš¸ê¸° ê¸°ì¤€:
- slope < -0.5: ì™¼ìª½ ì°¨ì„ 
- slope > 0.5: ì˜¤ë¥¸ìª½ ì°¨ì„ 

```Python

def calculate_center_line(frame, lane_lines):
    if len(lane_lines) == 2:
        left_line = lane_lines[0][0]
        right_line = lane_lines[1][0]
        center_line = [...]
        return [center_line]

```

- ê²€ì¶œëœ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„ ìœ¼ë¡œë¶€í„° ì°¨ëŸ‰ì´ ìœ„ì¹˜í•œ ë„ë¡œì˜ ì¤‘ì•™ì„ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.


ì¤‘ì•™ì„  ì‹œê°í™”

```Python

def display_center_line(frame, center_line):
    cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 0), 5)
    distance_cm = abs(x2 - x1) * 0.05
    label = f'{distance_cm:.2f} cm'
    cv2.putText(frame, label, ...)


```

- ê²€ì¶œëœ ì¤‘ì‹¬ì„ ì„ íŒŒë€ìƒ‰ ì„ ìœ¼ë¡œ ê·¸ë¦½ë‹ˆë‹¤.
- ì¤‘ì‹¬ì„  ê¸¸ì´ë¥¼ í”½ì…€ ë‹¨ìœ„ì—ì„œ cmë¡œ ë³€í™˜(í”½ì…€ ë‹¹ 0.05m ê°€ì •)í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.


YOLOë¥¼ í†µí•œ ì°¨ëŸ‰ íƒì§€

```Python

def car_detect(frame, model, confThreshold=0.5):
    results = model(frame)
    for result in results:
        for box in boxes:
            label = f'{model.names[class_id]} {confidence:.2f}'
            cv2.rectangle(frame, ...)
            cv2.putText(frame, ...)


```

- YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì°¨ëŸ‰ ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
- ì‹ ë¢°ë„(confidence)ê°€ confThreshold=0.5 ì´ìƒì¸ ì°¨ëŸ‰ë§Œ í™”ë©´ì— ê²½ê³„ ìƒìì™€ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.


ë©”ì¸ ë£¨í”„

```Python

while capture.isOpened():
    ret, frame = capture.read()
    edges = detect_edges(frame)
    cropped_edges = region_of_interest(edges)
    line_segments = detect_line_segments(cropped_edges)
    lane_lines = average_slope_intercept(frame, line_segments)
    center_line = calculate_center_line(frame, lane_lines)
    frame_with_center = display_center_line(frame, center_line)
    final_frame = car_detect(frame_with_center, model)
    cv2.imshow("Lane and Car Detection", final_frame)

```

ë§¤ í”„ë ˆì„ë§ˆë‹¤ 
- ì°¨ì„ ì˜ ì—£ì§€ë¥¼ ê²€ì¶œí•˜ê³  ROIë¥¼ ì ìš©.
- í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì§ì„ ì„ ê²€ì¶œí•˜ì—¬ ì°¨ì„  ë° ì¤‘ì‹¬ì„ ì„ ê³„ì‚°.
- YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ ì°¨ëŸ‰ì„ íƒì§€.
- ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥

------------------------------------------------------------------------------------
test(ros_opencv).py

ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì´ˆê¸°í™”

```Python

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import mediapipe as mp
import numpy as np
import time

```

- rclpy: ROS 2 íŒŒì´ì¬ í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ROS 2 ë…¸ë“œë¥¼ ìƒì„± ë° ê´€ë¦¬í•©ë‹ˆë‹¤.
- sensor_msgs.msg.Image: ROS 2ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ë©”ì‹œì§€ íƒ€ì….
- cv_bridge.CvBridge: ROS ì´ë¯¸ì§€ ë©”ì‹œì§€(sensor_msgs/Image)ë¥¼ OpenCV ì´ë¯¸ì§€(numpy array)ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬.
- mediapipe: í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•œ AI ëª¨ë¸ ì œê³µ.
- cv2: OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ì²˜ë¦¬ ë° HOG(Histogram of Oriented Gradients) ê¸°ë°˜ ì‚¬ëŒ ê²€ì¶œì„ ìˆ˜í–‰.

PoseEstimationNode í´ë˜ìŠ¤

```Python

# ì´ˆê¸°í™” (__init__)
class PoseEstimationNode(Node):
    def __init__(self):
        super().__init__('pose_estimation_node')

```

- ROS 2 ë…¸ë“œë¥¼ ìƒì„±í•˜ë©°, ì´ë¦„ì€ pose_estimation_nodeì…ë‹ˆë‹¤.


```Python

# ì´ë¯¸ì§€ êµ¬ë…
self.subscription = self.create_subscription(
    Image,
    '/camera/image_raw',  # ì¹´ë©”ë¼ì—ì„œ ë°œí–‰ë˜ëŠ” ì´ë¯¸ì§€ í† í”½
    self.image_callback,
    1
)

```

- ROS 2 ì´ë¯¸ì§€ í† í”½(/camera/image_raw)ì„ êµ¬ë…í•˜ë©°, ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ìˆ˜ì‹ ë  ë•Œë§ˆë‹¤ image_callback í•¨ìˆ˜ê°€ í˜¸ì¶œë©ë‹ˆë‹¤.

```Python

# CvBridge ì´ˆê¸°í™”
self.bridge = CvBridge()

```

- ROS 2 ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê±°ë‚˜, ë°˜ëŒ€ë¡œ ë³€í™˜í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

```Python

# MediaPipe í¬ì¦ˆ ì¶”ì •
self.mp_pose = mp.solutions.pose
self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, model_complexity=2)


```

- MediaPipeì˜ í¬ì¦ˆ ì¶”ì • ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
- min_detection_confidence: í¬ì¦ˆ ê²€ì¶œ ìµœì†Œ ì‹ ë¢°ë„.
- min_tracking_confidence: í¬ì¦ˆ ì¶”ì  ìµœì†Œ ì‹ ë¢°ë„.
- model_complexity: ëª¨ë¸ ë³µì¡ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (0, 1, 2 ì¤‘ ì„ íƒ)

```Python

# HOG ì‚¬ëŒ ê²€ì¶œê¸°
self.hog = cv2.HOGDescriptor()
self.hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

```

- OpenCVì˜ HOG(Histogram of Oriented Gradients) ê¸°ë°˜ ì‚¬ëŒ ê²€ì¶œê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.


```Python

# íƒ€ì´ë¨¸
self.timer = self.create_timer(1.0, self.timer_callback)

```

- 1ì´ˆë§ˆë‹¤ timer_callback í•¨ìˆ˜ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.


```Python

# FPS ê³„ì‚°ì„ ìœ„í•œ ì‹œê°„ ì´ˆê¸°í™”
self.start_time = time.time()

```

```Python

# ì´ë¯¸ì§€ ì½œë°± í•¨ìˆ˜ (image_callback)
def image_callback(self, msg):
    self.get_logger().info('Received image message')

```

- ì—­í• : ROS 2 ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ë©´ í˜¸ì¶œë˜ì–´ í¬ì¦ˆ ì¶”ì • ë° ì‚¬ëŒ ê²€ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```Python

# ì´ë¯¸ì§€ ë³€í™˜
frame = self.bridge.imgmsg_to_cv2(msg, 'bgr8')

```

- ROS 2 ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCV í˜•ì‹(numpy array)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```Python

# HOG ê¸°ë°˜ ì‚¬ëŒ ê²€ì¶œ
gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
boxes, weights = self.hog.detectMultiScale(gray, winStride=(8, 8), padding=(8, 8), scale=1.05)


```

- ì…ë ¥ ì´ë¯¸ì§€ë¥¼ í‘ë°±ìœ¼ë¡œ ë³€í™˜ í›„ HOG ì‚¬ëŒ ê²€ì¶œê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- winStride: íƒìƒ‰ ì°½ì˜ ì´ë™ ê°„ê²©.
- padding: íƒìƒ‰ ì°½ ì™¸ê³½ íŒ¨ë”©.
- scale: ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ë¹„ìœ¨.

```Python

# ì‚¬ëŒ ê²€ì¶œ í›„ í¬ì¦ˆ ì¶”ì •
for (x, y, w, h) in boxes:
    person_frame = frame[y:y+h, x:x+w]
    rgb_person_frame = cv2.cvtColor(person_frame, cv2.COLOR_BGR2RGB)
    result_pose = self.pose.process(rgb_person_frame)
    if result_pose.pose_landmarks:
        self.mp_drawing.draw_landmarks(person_frame, result_pose.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)


```

- ê²€ì¶œëœ ì‚¬ëŒ ì˜ì—­ì„ ì˜ë¼ë‚¸ í›„ RGBë¡œ ë³€í™˜í•˜ì—¬ MediaPipe í¬ì¦ˆ ì¶”ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- í¬ì¦ˆ ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ë©´ draw_landmarksë¡œ í¬ì¦ˆë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.


```Python

# FPS ê³„ì‚°
fps = 1.0 / (time.time() - self.start_time)
cv2.putText(frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

```

- í”„ë ˆì„ ì²˜ë¦¬ ì†ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.

```Python

# ê²°ê³¼ ì¶œë ¥
cv2.imshow('MJPEG Image', frame)
cv2.waitKey(1)

```

```Python

# íƒ€ì´ë¨¸ ì½œë°± í•¨ìˆ˜ (timer_callback)
def timer_callback(self):
    self.get_logger().info('Timer triggered!')


```

- ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, í˜„ì¬ëŠ” ë…¸ë“œ ìƒíƒœë¥¼ ë¡œê¹…í•˜ëŠ” ê°„ë‹¨í•œ ì—­í• ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.


```Python

def main(args=None):
    rclpy.init(args=args)
    node = PoseEstimationNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("Node interrupted by user")
    finally:
        node.destroy_node()


```

- rclpy.spin(node): ë…¸ë“œë¥¼ ì‹¤í–‰ ìƒíƒœë¡œ ìœ ì§€í•˜ë©°, ë©”ì‹œì§€ê°€ ìˆ˜ì‹ ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.
- KeyboardInterrupt: ì‚¬ìš©ìê°€ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ë©´ ì¢…ë£Œ ì²˜ë¦¬.

